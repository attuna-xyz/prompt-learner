[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prompt Learner",
    "section": "",
    "text": "Why Prompt-Learner?\n  \n  \n    \n     Installation\n  \n  \n    \n     Getting started\n  \n  \n    \n     GitHub\n  \n  \n    \n     Try The App"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Prompt Learner",
    "section": "Install",
    "text": "Install\n1pip install prompt-learner\n\n1\n\nInstall prompt-learner\n\n\n\nRead Philosophy\n\n\n\n\n\n\nAssembling & Optimizing Prompts\nA prompt is composed of distinct modules.\nEach module can be optimized both on its own, and as a part of the entire system.\n\n1. The task type\n2. The task description\n3. A few examples\n4. Instructions for output format\n5. Custom Prompt Technique specific Instructions\n\n\nPrompt Learner is designed to enable assembly and optimzation of prompts.\nIt encourages rapid experimentation, easy maintainability and frictionless updating of prompts."
  },
  {
    "objectID": "index.html#quickstart",
    "href": "index.html#quickstart",
    "title": "Prompt Learner",
    "section": "Quickstart",
    "text": "Quickstart\n\n\n\n\nSee the getting started tutorial for a more in-depth introduction to Prompt-learner."
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Using Prompt-Learner\nHere is a step by step approach to run prompt-learner to optimize and assemble a prompt for any classification task.\n\nPrompt-learner for Classification Task\n\nDescribe your task\n\n\nclassification_description = \"You have to classify customer texts as Urgent or Not Urgent\"\n\n\nSpecify allowed labels\n\n\nclassification_labels = [\"Urgent\", \"Not Urgent\"]\n\n\nCreate the classification task\n\n\nfrom prompt_learner.tasks import classification\nclassification_task = classification.ClassificationTask(description=classification_description, allowed_labels=classification_labels)\n\n\nAdd a few examples to your task\n\n\nfrom prompt_learner.examples import Example\nclassification_task.add_example(Example(text=\"I need help\", label=\"Urgent\"))\nclassification_task.add_example(Example(text=\"I got my package\", label=\"Not Urgent\"))\n\n\nChoose an LLM Provider template\n\n\nfrom prompt_learner.templates import markdown_template\nmarkdown_template = markdown_template.MarkdownTemplate(task=classification_task)\n\n\nRun any Optimizer to sample Examples for inserting in prompt\n\n\nfrom prompt_learner.selectors import random_sampler\nsampler = random_sampler.RandomSampler(num_samples=1, task=classification_task)\nsampler.select_examples()\n\n\nAssemble the prompt with selected examples, and any prompting technique (example, Chain of Thought)\n\n\nfrom prompt_learner.prompts import cot\ngpt_prompt = cot.CoT(template=markdown_template)\ngpt_prompt.assemble_prompt()\n\n\nView your prompt!\n\n\ngpt_prompt.prompt\n\n\nEvaluate performance of your prompt.\n\n\nfrom prompt_learner.evals.metrics.accuracy import Accuracy\nacc_score = Accuracy(classification_task).compute(gpt_prompt, OpenAI())\n# automatically runs evaluation on all examples that are not in the prompt\n\n\nInfer using your prompt\n\n\nfrom prompt_learner.adapters.openai import OpenAI\ngpt_prompt.add_inference(\"My package is missing\")\n\nanswer = classification_task.predict(OpenAI(), gpt_prompt.prompt)"
  },
  {
    "objectID": "contribute/index.html",
    "href": "contribute/index.html",
    "title": "Contribute",
    "section": "",
    "text": "Contribute\nCheck out our contributing guide for details! Guides for setting up an environment and getting started are here.",
    "crumbs": [
      "Contribute"
    ]
  },
  {
    "objectID": "tutorials/getting_started.html",
    "href": "tutorials/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "Using Prompt-Learner\nHere is a step by step approach to run prompt-learner to optimize and assemble a prompt for any classification task.\n\nPrompt-learner for Classification Task\n\nDescribe your task\n\n\nclassification_description = \"You have to classify customer texts as Urgent or Not Urgent\"\n\n\nSpecify allowed labels\n\n\nclassification_labels = [\"Urgent\", \"Not Urgent\"]\n\n\nCreate the classification task\n\n\nfrom prompt_learner.tasks import classification\nclassification_task = classification.ClassificationTask(description=classification_description, allowed_labels=classification_labels)\n\n\nAdd a few examples to your task\n\n\nfrom prompt_learner.examples import Example\nclassification_task.add_example(Example(text=\"I need help\", label=\"Urgent\"))\nclassification_task.add_example(Example(text=\"I got my package\", label=\"Not Urgent\"))\n\n\nChoose an LLM Provider template\n\n\nfrom prompt_learner.templates import markdown_template\nmarkdown_template = markdown_template.MarkdownTemplate(task=classification_task)\n\n\nRun any Optimizer to sample Examples for inserting in prompt\n\n\nfrom prompt_learner.selectors import random_sampler\nsampler = random_sampler.RandomSampler(num_samples=1, task=classification_task)\nsampler.select_examples()\n\n\nAssemble the prompt with selected examples, and any prompting technique (example, Chain of Thought)\n\n\nfrom prompt_learner.prompts import cot\ngpt_prompt = cot.CoT(template=markdown_template)\ngpt_prompt.assemble_prompt()\n\n\nView your prompt!\n\n\ngpt_prompt.prompt\n\n\nEvaluate performance of your prompt.\n\n\nfrom prompt_learner.evals.metrics.accuracy import Accuracy\nacc_score = Accuracy(classification_task).compute(gpt_prompt, OpenAI())\n# automatically runs evaluation on all examples that are not in the prompt\n\n\nInfer using your prompt\n\n\nfrom prompt_learner.adapters.openai import OpenAI\ngpt_prompt.add_inference(\"My package is missing\")\n\nanswer = classification_task.predict(OpenAI(), gpt_prompt.prompt)"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing to Prompt-Learner",
    "section": "",
    "text": "Contributing to Prompt-Learner\nWe love new contributors!"
  },
  {
    "objectID": "contribute/01_environment.html",
    "href": "contribute/01_environment.html",
    "title": "Setting up a development environment",
    "section": "",
    "text": "Setting up a development environment",
    "crumbs": [
      "Contribute",
      "Setting up a development environment"
    ]
  },
  {
    "objectID": "why.html",
    "href": "why.html",
    "title": "Why Prompt-Learner?",
    "section": "",
    "text": "We are practitioners and researchers ourselves and we keep running into the same problem again and again of writing a new prompt string from scratch, and then optmizing and maintaing it over time.\nWe believe that a prompt in itself is too big a unit and too critical a piece of the puzzle to not be broken down into simpler meaningful parts.\nWe also believe that swapping in and swapping out different alternatives for these modular parts of a prompt in a systematic and optimization centric paradigm will lead to optmized, maintainable and more understandable prompting.\nThere is no systematic and simple tool that allows users to control the granular parts of a prompt and optimize it, and we want to solve this problem with prompt-learner.",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "why.html#what-is-prompt-learner",
    "href": "why.html#what-is-prompt-learner",
    "title": "Why Prompt-Learner?",
    "section": "",
    "text": "Prompt Learner focuses on two aspects of prompting -\n\nConverting a prompt from a single string(or fstring) to well defined modular parts that can eventually be assembled to create the eventual prompt.\nEnable users to programatically modify, replace, mix and match different alternatives in each module of the prompt to optimize the final prompt for performance.",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "why.html#community",
    "href": "why.html#community",
    "title": "Why Prompt-Learner?",
    "section": "Community",
    "text": "Community\nWe are building a community of developers who believe that prompting is here to stay, and are excited about tinkering with it programatically and systematically. Join our discord.\n\nFor discussions, issues and requests regarding the library, join us on GitHub",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "why.html#getting-started",
    "href": "why.html#getting-started",
    "title": "Why Prompt-Learner?",
    "section": "Getting started",
    "text": "Getting started\nIf you’re interested in trying Prompt-learner we recommend the getting started tutorial.",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installation",
    "section": "",
    "text": "Installation"
  },
  {
    "objectID": "concepts/Templates.html",
    "href": "concepts/Templates.html",
    "title": "Templates",
    "section": "",
    "text": "Templates\nEvery LLM provider (adapter) and in turn, every LLM, has its own specific nuances and formatting. This is captured in the template. For example, the Claude family of models prefer information enclosed within xml tags. An Anthropic Template takes care of this.\nMore generally, a template also defines the backbone of any prompt. It is composed of a few modular parts -\n1. A descriptor : This is the task description.\n2. Preambles : Prediction Preamble, Examples Preamble - These are blobs of text the come before one instucts the model to give a specific output or when one lets the model know that a few examples for the task will follow.\n3. Example Formatting : A way to format and insert selected examples into the prompt.\n4. Inference formatting : A way to insert the sample for inference into the prompt.",
    "crumbs": [
      "Why Prompt-Learner?",
      "Templates"
    ]
  },
  {
    "objectID": "concepts/Adapters.html",
    "href": "concepts/Adapters.html",
    "title": "Adapters",
    "section": "",
    "text": "Adapters are your connections to LLM providers. We currently support Anthropic and OpenAI. It is very easy to add a new adapter by extending the base Adapter class.\nAdapter should ideally have a corresponding template to it since different LLMs have different formatting of prompts that they are best suited for.\nTo use an adapter, you simply need to import an adapter of your choice.\n\nfrom prompt_learner.adapters.openai import OpenAI\n\nRunning any inference requires an adapter as a paramter. The inference call is made through the specified LLM adapter.\n\nclassification_task.predict(OpenAI(), gpt_prompt.prompt)",
    "crumbs": [
      "Why Prompt-Learner?",
      "Adapters"
    ]
  },
  {
    "objectID": "concepts/Selectors.html",
    "href": "concepts/Selectors.html",
    "title": "Selectors",
    "section": "",
    "text": "Selectors are a part of Optimizers and work on picking n best examples from the entire set of user provided examples for the task.\nA selector can be as simple as a random example selector that randomly picks up n examples from all examples.\nA selector can also be arbitrarly complex and use feedback from LLM calls on a set of held out examples to decide the importance of a given example. It can use these signals to pick the n best examples to insert into the prompt.\nA selector can also generate synthetic examples and select among them via similar feedback signals.\n\n\nfrom prompt_learner.selectors import random_sampler\nrandom_sampler.RandomSampler(num_samples=2,task=classification_task)\n\nThis will select 2 samples from the set of all examples attached to the classification_task. These 2 selected samples will be inserted into the prompt as few shot examples when the prompt is assembled.",
    "crumbs": [
      "Why Prompt-Learner?",
      "Selectors"
    ]
  },
  {
    "objectID": "concepts/TasksExamples.html",
    "href": "concepts/TasksExamples.html",
    "title": "Tasks & Examples",
    "section": "",
    "text": "Tasks & Examples\nA user has to be always provide prompt-learner with task and examples.   A task comprises of the description of the task, the type of task and a valid set of labels for the task(if applicable).\nAn example is a data sample for the task and will have a corresponding text and label(if applicable).\nA combination of a well-specified task and examples guides the prompt-learning pipeline.",
    "crumbs": [
      "Why Prompt-Learner?",
      "Tasks & Examples"
    ]
  },
  {
    "objectID": "concepts/Architecture.html",
    "href": "concepts/Architecture.html",
    "title": "Architecture",
    "section": "",
    "text": "Architecture\n Prompt-learner runs on the above architecture.\nStarting from the left, the user has to decide on 3 aspects -\n1. The Task\n2. A set of Examples\n3. An LLM Adapter\n\nA task and examples feed into the template of choice (Claude, Open AI..).\nThe task and examples also interact with selectors which can pick the best n examples for the task using statistical and machine learning techniques.\nThese selected examples slot into the template, along with any custom instructions from any prompting technique( such as adding ‘think step by step’ for chain of thought prompting) comprise the final prompt.\nThe prompt invokes the LLM through the adapter with any given inference sample to produce the final output.",
    "crumbs": [
      "Why Prompt-Learner?",
      "Architecture"
    ]
  },
  {
    "objectID": "why.html#why-use-prompt-learner",
    "href": "why.html#why-use-prompt-learner",
    "title": "Why Prompt-Learner?",
    "section": "",
    "text": "We are practitioners and researchers ourselves and we keep running into the same problem again and again of writing a new prompt string from scratch, and then optmizing and maintaing it over time.\nWe believe that a prompt in itself is too big a unit and too critical a piece of the puzzle to not be broken down into simpler meaningful parts.\nWe also believe that swapping in and swapping out different alternatives for these modular parts of a prompt in a systematic and optimization centric paradigm will lead to optmized, maintainable and more understandable prompting.\nThere is no systematic and simple tool that allows users to control the granular parts of a prompt and optimize it, and we want to solve this problem with prompt-learner.",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "why.html#focus-areas-of-prompt-learner",
    "href": "why.html#focus-areas-of-prompt-learner",
    "title": "Why Prompt-Learner?",
    "section": "Focus Areas of Prompt-Learner",
    "text": "Focus Areas of Prompt-Learner\nPrompt Learner focuses on two aspects of prompting -\n\nConverting a prompt from a single string(or fstring) to well defined modular parts that can eventually be assembled to create the eventual prompt.\nEnable users to programatically modify, replace, mix and match different alternatives in each module of the prompt to optimize the final prompt for performance.",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "tutorials/optimize_customer_text_classifier.html",
    "href": "tutorials/optimize_customer_text_classifier.html",
    "title": "Optimizing a Prompt",
    "section": "",
    "text": "Using Prompt-Learner\nWe will use prompt-learner to optimize the prompt for a customer support text classifier task.\n\nPrompt-learner for Classification Task\n\nDescribe your task\n\n\nclassification_description = \"You have to classify customer texts as Urgent or Not Urgent\"\n\n\nSpecify allowed labels\n\n\nclassification_labels = [\"Urgent\", \"Not Urgent\"]\n\n\nCreate the classification task\n\n\nfrom prompt_learner.tasks import classification\nclassification_task = classification.ClassificationTask(description=classification_description, allowed_labels=classification_labels)\n\n\nAdd a few examples to your task\n\n\nfrom prompt_learner.examples import Example\nclassification_task.add_example(Example(text=\"I need help\", label=\"Urgent\"))\nclassification_task.add_example(Example(text=\"I got my package\", label=\"Not Urgent\"))\n\n\nChoose an LLM Provider template\n\n\nfrom prompt_learner.templates import markdown_template\nmarkdown_template = markdown_template.MarkdownTemplate(task=classification_task)\n\n\nRun any Optimizer to sample Examples for inserting in prompt\n\n\nfrom prompt_learner.selectors import random_sampler\nsampler = random_sampler.RandomSampler(num_samples=1, task=classification_task)\nsampler.select_examples()\n\n\nAssemble the prompt with selected examples, and any prompting technique (example, Chain of Thought)\n\n\nfrom prompt_learner.prompts import cot\ngpt_prompt = cot.CoT(template=markdown_template)\ngpt_prompt.assemble_prompt()\n\n\nView your prompt!\n\n\ngpt_prompt.prompt\n\n\nEvaluate performance of your prompt.\n\n\nfrom prompt_learner.evals.metrics.accuracy import Accuracy\nacc_score = Accuracy(classification_task).compute(gpt_prompt, OpenAI())\n# automatically runs evaluation on all examples that are not in the prompt\n\n\nInfer using your prompt\n\n\nfrom prompt_learner.adapters.openai import OpenAI\ngpt_prompt.add_inference(\"My package is missing\")\n\nanswer = classification_task.predict(OpenAI(), gpt_prompt.prompt)"
  }
]