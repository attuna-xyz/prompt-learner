[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prompt Learner",
    "section": "",
    "text": "Why Prompt-Learner?\n  \n  \n    \n     Installation\n  \n  \n    \n     Getting started\n  \n  \n    \n     GitHub"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Prompt Learner",
    "section": "Install",
    "text": "Install\n1pip install prompt-learner\n\n1\n\nInstall prompt-learner\n\n\n\nShow Philosophy\n\n\n\n\n\n\nAssembling & Learning Prompts\nA prompt is composed of distinct modules.\nEach module can be optimized both on its own, and as a part of the entire system.\n\n1. The task type\n2. The task description\n3. A few examples\n4. Instructions for output format\n5. Custom Prompt Technique specific Instructions\n\n\nPrompt Learner is designed to enable assembly and optimzation of prompts."
  },
  {
    "objectID": "index.html#quickstart",
    "href": "index.html#quickstart",
    "title": "Prompt Learner",
    "section": "Quickstart",
    "text": "Quickstart\nSee the getting started tutorial for a more in-depth introduction to Prompt-learner. Below is a quick overview.\n\nEnsure you install prompt-learner first\nPick your task type\nDescribe the task\nAdd a few examples\nChoose an LLM adapter\nSelect some examples by running an optimizer\nGet the final prompt\nInfer on your new sample!"
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Using Prompt-Learner\nHere is a step by step approach to run prompt-learner to optimize and assemble a prompt for any classification task.\n\nPrompt-learner for Classification Task\n\nDescribe your task\n\n\nclassification_description = \"You have to classify customer texts as Urgent or Not Urgent\"\n\n\nSpecify allowed labels\n\n\nclassification_labels = [\"Urgent\", \"Not Urgent\"]\n\n\nCreate the classification task\n\n\nfrom prompt_learner.tasks import classification\nclassification_task = classification.ClassificationTask(description=classification_description, allowed_labels=classification_labels)\n\n\nAdd a few examples to your task\n\n\nfrom prompt_learner.examples import Example\nclassification_task.add_example(Example(text=\"I need help\", label=\"Urgent\"))\nclassification_task.add_example(Example(text=\"I got my package\", label=\"Not Urgent\"))\n\n\nChoose an LLM Provider template\n\n\nfrom prompt_learner.templates import openai_template\nopenai_template = openai_template.OpenAICompletionTemplate(task=classification_task)\n\n\nRun any Optimizer to sample Examples for inserting in prompt\n\n\nfrom prompt_learner.optimizers.selectors import random_sampler\nsampler = random_sampler.RandomSampler(num_samples=1, task=classification_task)\nsampler.select_examples()\n\n\nAssemble the prompt with selected examples, and any prompting technique (example, Chain of Thought)\n\n\nfrom prompt_learner.prompts import cot\nopenai_prompt = cot.CoT(template=openai_template, selector=sampler)\nopenai_prompt.assemble_prompt()\n\n\nView your prompt!\n\n\nopenai_prompt.prompt\n\n\nInfer using your prompt\n\n\nfrom prompt_learner.adapters.openai import OpenAI\nopenai_prompt.add_inference(\"My package is missing\")\n\nanswer = classification_task.predict(OpenAI(), openai_prompt.prompt)"
  },
  {
    "objectID": "contribute/index.html",
    "href": "contribute/index.html",
    "title": "Contribute",
    "section": "",
    "text": "Contribute\nCheck out our contributing guide for details! Guides for setting up an environment and getting started are here.",
    "crumbs": [
      "Contribute"
    ]
  },
  {
    "objectID": "tutorials/getting_started.html",
    "href": "tutorials/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "Using Prompt-Learner\nHere is a step by step approach to run prompt-learner to optimize and assemble a prompt for any classification task.\n\nPrompt-learner for Classification Task\n\nDescribe your task\n\n\nclassification_description = \"You have to classify customer texts as Urgent or Not Urgent\"\n\n\nSpecify allowed labels\n\n\nclassification_labels = [\"Urgent\", \"Not Urgent\"]\n\n\nCreate the classification task\n\n\nfrom prompt_learner.tasks import classification\nclassification_task = classification.ClassificationTask(description=classification_description, allowed_labels=classification_labels)\n\n\nAdd a few examples to your task\n\n\nfrom prompt_learner.examples import Example\nclassification_task.add_example(Example(text=\"I need help\", label=\"Urgent\"))\nclassification_task.add_example(Example(text=\"I got my package\", label=\"Not Urgent\"))\n\n\nChoose an LLM Provider template\n\n\nfrom prompt_learner.templates import openai_template\nopenai_template = openai_template.OpenAICompletionTemplate(task=classification_task)\n\n\nRun any Optimizer to sample Examples for inserting in prompt\n\n\nfrom prompt_learner.optimizers.selectors import random_sampler\nsampler = random_sampler.RandomSampler(num_samples=1, task=classification_task)\nsampler.select_examples()\n\n\nAssemble the prompt with selected examples, and any prompting technique (example, Chain of Thought)\n\n\nfrom prompt_learner.prompts import cot\nopenai_prompt = cot.CoT(template=openai_template, selector=sampler)\nopenai_prompt.assemble_prompt()\n\n\nView your prompt!\n\n\nopenai_prompt.prompt\n\n\nInfer using your prompt\n\n\nfrom prompt_learner.adapters.openai import OpenAI\nopenai_prompt.add_inference(\"My package is missing\")\n\nanswer = classification_task.predict(OpenAI(), openai_prompt.prompt)"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing to Prompt-Learner",
    "section": "",
    "text": "Contributing to Prompt-Learner\nWe love new contributors!"
  },
  {
    "objectID": "contribute/01_environment.html",
    "href": "contribute/01_environment.html",
    "title": "Setting up a development environment",
    "section": "",
    "text": "Setting up a development environment",
    "crumbs": [
      "Contribute",
      "Setting up a development environment"
    ]
  },
  {
    "objectID": "why.html",
    "href": "why.html",
    "title": "Why Prompt-Learner?",
    "section": "",
    "text": "Never write strings again.",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "why.html#what-is-prompt-learner",
    "href": "why.html#what-is-prompt-learner",
    "title": "Why Prompt-Learner?",
    "section": "What is Prompt-Learner?",
    "text": "What is Prompt-Learner?\nWe break down prompts into modular parts. And optimize them to finally assemble them.\n\nprint(5)\n\n5",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "why.html#community",
    "href": "why.html#community",
    "title": "Why Prompt-Learner?",
    "section": "Community",
    "text": "Community\nCommunity discussions primarily take place on GitHub",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "why.html#getting-started",
    "href": "why.html#getting-started",
    "title": "Why Prompt-Learner?",
    "section": "Getting started",
    "text": "Getting started\nIf you’re interested in trying Prompt-learner we recommend the getting started tutorial.",
    "crumbs": [
      "Why Prompt-Learner?"
    ]
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installation",
    "section": "",
    "text": "Installation"
  },
  {
    "objectID": "concepts/Templates.html",
    "href": "concepts/Templates.html",
    "title": "Templates",
    "section": "",
    "text": "Templates\nEvery LLM provider (adapter) and in turn, every LLM, has its own specific nuances and formatting. This is captured in the template. For example, the Claude family of models prefer information enclosed within xml tags. An Anthropic Template takes care of this.\nMore generally, a template also defines the backbone of any prompt. It is composed of a few modular parts - 1. A descriptor : This is the task description 2. Preambles : Prediction Preamble, Examples Preamble - These are blobs of text the come before one instucts the model to give a specific output or when one lets the model know that a few examples for the task will follow. 3. Example Formatting : A way to format and insert selected examples into the prompt. 4. Inference formatting : A way to insert the sample for inference into the prompt",
    "crumbs": [
      "Why Prompt-Learner?",
      "Templates"
    ]
  },
  {
    "objectID": "concepts/Adapters.html",
    "href": "concepts/Adapters.html",
    "title": "Adapters",
    "section": "",
    "text": "Adapters are your connections to LLM providers. We currently support Anthropic and OpenAI. It is very easy to add a new adapter by extending the base Adapter class.\nAdapter should ideally have a corresponding template to it since different LLMs have different formatting of prompts that they are best suited for.\nTo use an adapter, you simply need to import an adapter of your choice.\n\nfrom prompt_learner.adapters.openai import OpenAI\n\nRunning any inference requires an adapter as a paramter. The inference call is made through the specified LLM adapter.\n\nclassification_task.predict(OpenAI(), openai_prompt.prompt)",
    "crumbs": [
      "Why Prompt-Learner?",
      "Adapters"
    ]
  },
  {
    "objectID": "concepts/Selectors.html",
    "href": "concepts/Selectors.html",
    "title": "Selectors",
    "section": "",
    "text": "Selectors are a part of Optimizers and work on picking n best examples from the entire set of user provided examples for the task.\nA selector can be as simple as a random example selector that randomly picks up n examples from all examples.\nA selector can also be arbitrarly complex and use feedback from LLM calls on a set of held out examples to decide the importance of a given example. It can use these signals to pick the n best examples to insert into the prompt.\nA selector can also generate synthetic examples and select among them via similar feedback signals.\n\n\nfrom prompt_learner.optimizers.selectors import random_sampler\nrandom_sampler.RandomSampler(num_samples=2,task=classification_task)\n\nThis will select 2 samples from the set of all examples attached to the classification_task. These 2 selected samples will be inserted into the prompt as few shot examples when the prompt is assembled.",
    "crumbs": [
      "Why Prompt-Learner?",
      "Selectors"
    ]
  },
  {
    "objectID": "concepts/TasksExamples.html",
    "href": "concepts/TasksExamples.html",
    "title": "Tasks & Examples",
    "section": "",
    "text": "Tasks & Examples\nA user has to be always provide prompt-learner with task and examples.   A task comprises of the description of the task, the type of task and a valid set of labels for the task(if applicable).\nAn example is a data sample for the task and will have a corresponding text and label(if applicable).\nA combination of a well-specified task and examples guides the prompt-learning pipeline.",
    "crumbs": [
      "Why Prompt-Learner?",
      "Tasks & Examples"
    ]
  },
  {
    "objectID": "concepts/Architecture.html",
    "href": "concepts/Architecture.html",
    "title": "Architecture",
    "section": "",
    "text": "Architecture\nOverall design explained",
    "crumbs": [
      "Why Prompt-Learner?",
      "Architecture"
    ]
  }
]