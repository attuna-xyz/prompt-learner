---
title: "Getting started"
sidebar: getting-started
---
# Using Prompt-Learner
Here is a step by step approach to run prompt-learner to optimize and assemble a prompt for any classification task.

### Prompt-learner for Classification Task

1. Describe your task
```{python}
#| eval: false
classification_description = "You have to classify customer texts as Urgent or Not Urgent"
```

2. Specify allowed labels
```{python}
classification_labels = ["Urgent", "Not Urgent"]
```
3. Create the classification task
```{python}
#| eval: false
from prompt_learner.tasks import classification
classification_task = classification.ClassificationTask(description=classification_description, allowed_labels=classification_labels)
```
4. Add a few examples to your task
```{python}
#| eval: false
from prompt_learner.examples import Example
classification_task.add_example(Example(text="I need help", label="Urgent"))
classification_task.add_example(Example(text="I got my package", label="Not Urgent"))
```
5. Choose an LLM Provider template
```{python}
#| eval: false
from prompt_learner.templates import markdown
markdown_template = markdown.MarkdownTemplate(task=classification_task)
```
6. Run any Optimizer to sample Examples for inserting in prompt
```{python}
#| eval: false
from prompt_learner.selectors import random_sampler
sampler = random_sampler.RandomSampler(num_samples=1, task=classification_task)
sampler.select_examples()
```
7. Assemble the prompt with selected examples, and any prompting technique (example, Chain of Thought)

```{python}
#| eval: false
from prompt_learner.prompts import cot
gpt_prompt = cot.CoT(template=markdown_template)
gpt_prompt.assemble_prompt()
```
8. View your prompt!
```{python}
#| eval: false
print(gpt_prompt.prompt)
```
9. Evaluate performance of your prompt.
```{python}
#| eval: false
from prompt_learner.evals.metrics.accuracy import Accuracy
acc_score = Accuracy(classification_task).compute(gpt_prompt, OpenAI())
# automatically runs evaluation on all examples that are not in the prompt
```
10. Infer using your prompt
```{python}
#| eval: false
from prompt_learner.adapters.openai import OpenAI
gpt_prompt.add_inference("My package is missing")

answer = classification_task.predict(OpenAI(), gpt_prompt.prompt)
```